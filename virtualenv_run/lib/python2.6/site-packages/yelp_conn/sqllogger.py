# -*- coding: utf-8 -*-
"""
SQL query logging by wrapping connections. See :class:`LoggingConnectionWrapper`

Logging can be done by printing to stdout or logging using a class which
implements the :class:`LoggingCursorListener` interface.  This module provides
an implementation which logs to :mod:`clog` :class:`ClogCursorListener`.

"""
import logging
import os
import re
import simplejson as json
import socket
import sys
import time
from contextlib import contextmanager

import clog

from yelp_conn import _import, wrappers
from yelp_conn import config
from yelp_conn.db_util import cursor_result_to_dict
from yelp_conn import sql
from yelp_conn.sql import canonicalize_sql_query, format_sql_table
from yelp_conn.sqlchecker import calc_explain_plan_scores
from yelp_conn.wrappers import DelegatingConnectionWrapper
from yelp_conn.wrappers import DelegatingCursorWrapper


# Keeps track of where log data is coming from, do not make this thread local
current_source = None

logger = logging.getLogger('sqllogger')

class LoggingCursorListener(object):
    """Interface for listeners to adhere to.

    If logging to stdout is not sufficient for your needs, subclass
    me and register your interest by adding to
    config.query_logging_listeners
    """

    def on_query(self, query_data):
        pass

    def on_explain_plan(self, explain_data):
        pass

    @classmethod
    def is_implementor(cls, obj):
        return hasattr(obj, 'on_query') and hasattr(obj, 'on_explain_plan')


class ClogCursorListener(object):
    """Logging listener for a Clog."""

    def __init__(self, log_name):
        self.log_name = log_name

    def build_log_entry(self, query_type, query_data):
        entry = json.dumps({'query_type': query_type, 'query_data': query_data})
        clog.log_line(self.log_name, entry)

    def on_query(self, query_data):
        self.build_log_entry('query', query_data)

    def on_explain_plan(self, explain_data):
        self.build_log_entry('explain', explain_data)


class ClogCursorTimingListener(ClogCursorListener):
    """Only log elapsed, timing and dbparams."""

    def build_log_entry(self, query_type, query_data):

        keys = query_data.keys()
        if not ('elapsed' in keys and 'time' in keys and 'dbparams' in keys):
            return
        entry = json.dumps({'query_type': query_type, 'query_data': {'elapsed': query_data['elapsed'],
                        'time': query_data['time'], 'dbparams': query_data['dbparams']}})
        clog.log_line(self.log_name, entry)

    def on_explain_plan(self, explain_data):
        pass

def get_db_params_from_conn(conn):
    return conn._delegate.get_host_info().split()[0], conn._delegate.port


class QueryExecuteProxy(object):

    def __init__(self, cursor, query, bind_values):
        self.cursor = cursor
        self.query = query
        self.bind_values = bind_values

    def execute(self):
        return self.cursor.execute(self.query, self.bind_values)

    def fill_query(self):
        return wrappers.fill_query(self.cursor, self.query, self.bind_values)


class QueryExecuteManyProxy(object):

    def __init__(self, cursor, query, bind_values):
        self.cursor = cursor
        self.query = query
        self.bind_values = bind_values

    def execute(self):
        return self.cursor.executemany(self.query, self.bind_values)

    def fill_query(self):
        bind_values = self.bind_values[0] if self.bind_values else {}
        return wrappers.fill_query(self.cursor, self.query, bind_values)


class LoggingCursorWrapper(DelegatingCursorWrapper):
    """ SQL Query Logger """

    def __init__(self, conn, cursor, logging_reporter):
        super(LoggingCursorWrapper, self).__init__(conn, cursor)
        self.reporter = logging_reporter

    def _log_and_execute(self, proxy):
        if not self.reporter.config.enabled_for(proxy.query):
            return proxy.execute()

        self._execute_explain(proxy)
        with self.reporter.log_timed_query(proxy.query) as log_data:
            log_data['rows'] = results = proxy.execute()
        return results

    def executemany(self, query, bind_vals=None):
        proxy = QueryExecuteManyProxy(self._delegate, query, bind_vals)
        return self._log_and_execute(proxy)

    def execute(self, query, bind_vals=None):
        proxy = QueryExecuteProxy(self._delegate, query, bind_vals)
        return self._log_and_execute(proxy)

    def _execute_explain(self, proxy):
        if (not self.reporter.config.explain_enabled or
                not sql.is_select_from_query(proxy.fill_query())):
            return

        query = proxy.query
        self._delegate.execute('EXPLAIN ' + query, proxy.bind_values)
        rows = self._delegate.fetchall()
        explain_data = cursor_result_to_dict(rows, self._delegate.description)
        self.reporter.log_explain(explain_data, query, proxy.fill_query())


class PrintingCursorWrapper(LoggingCursorWrapper):
    """Convenience cursor wrapper class for printing cursor activity to stdout"""
    def __init__(self, conn, cursor):
        reporter_config = LoggingReporterConfig(printing=True)
        reporter = LoggingReporter(conn, reporter_config )
        super(PrintingCursorWrapper, self).__init__(conn, cursor, reporter)


class ExplainingPrintingCursorWrapper(LoggingCursorWrapper):
    """Convenience cursor wrapper class for printing explain plan to stdout"""
    def __init__(self, conn, cursor):
        reporter_config  = LoggingReporterConfig(printingexplaining=True)
        reporter = LoggingReporter(conn, reporter_config)
        super(ExplainingPrintingCursorWrapper, self).__init__(
            conn, cursor, reporter)


class LoggingConnectionWrapper(DelegatingConnectionWrapper):
    """Logging connection wrapper provides hooks for logging queries

    This class has the following configuration settings which are
    disabled by default.

    * `enable_query_logging` enable query logging (still requires a
      `query_logging_listeners` to handle the logging)
    * `enable_query_logging_explain` - similar to enable_query_logging but for explain plans
    * `enable_query_printing` - enable printing queries to stdout
    * `enable_query_printingexplaining` - enable printing query explain plans to stdout
    * `enable_slow_query_logging` -log slow quries to tmp_slow_queries scribe log
    * `query_logging_callstack_filter` - only log queries which have a callstack that
      match this regex
    * `query_logging_filter` - only log queries which match this regex
    * `query_logging_listeners` is a list of classes (or names of classes) which
      implement the :class:`LoggingCursorListener` interface.  These classes are
      called to log queries.

    """

    CURSOR_CLASS = LoggingCursorWrapper

    def __init__(self, conn, db=None, role=None, **kwargs):
        super(LoggingConnectionWrapper, self).__init__(conn)
        reporter_config = LoggingReporterConfig(**kwargs)
        self.reporter = LoggingReporter(conn, reporter_config)

    def cursor(self, *args, **kwargs):
        return self.CURSOR_CLASS(
            self, self._delegate.cursor(*args, **kwargs), self.reporter)

    def commit(self):
        with self.reporter.log_timed_query('COMMIT'):
            self._delegate.commit()

    def rollback(self):
        with self.reporter.log_timed_query('ROLLBACK'):
            self._delegate.rollback()


def build_filter(filter):
    if isinstance(filter, basestring):
        return re.compile(filter)
    return filter


class LoggingReporterConfig(object):

    def __init__(self,
             normallogging=None,
             printing=None,
             printingexplaining=None,
             explaining=None,
             slowlogging=None,
             query_filter=None,
             stack_filter=None,
             **kwargs):
        """Load a configuration."""
        self.logging = normallogging or config.enable_query_logging
        self.printing = printing or config.enable_query_printing
        self.explain_printing = (printingexplaining or
            config.enable_query_printingexplaining)
        self.explain = explaining or config.enable_query_logging_explain
        self.slow_logging = slowlogging or config.enable_slow_query_logging
        self.query_filter = build_filter(
            query_filter or config.query_logging_filter.value)
        self.stack_filter = build_filter(
            stack_filter or config.query_logging_callstack_filter.value)
        self.listeners = self._setup_listeners()

    def _setup_listeners(self):
        """Return logging listeners from config.query_logging_listeners."""
        def build_listener(listener):
            if isinstance(listener, basestring):
                listener = _import.import_module_class(listener)()

            if isinstance(listener, (list, tuple)):
                module, args = listener[0], listener[1:]
                listener = _import.import_module_class(module)(*args)

            if LoggingCursorListener.is_implementor(listener):
                return listener

            msg = "Expected listener with LoggingCursorListener interface: %s"
            raise ValueError(msg % type(listener))

        return [build_listener(listener)
                for listener in config.query_logging_listeners]

    def enabled_for(self, query):
        if self.query_filter and self.query_filter.match(query):
            return True

        if self.stack_filter and self.stack_filter.match(showstack(2)):
            return True

        return not self.query_filter and not self.stack_filter

    @property
    def explain_enabled(self):
        return self.explain or self.explain_printing


class LoggingReporter(object):
    """Log queries using listeners."""

    def __init__(self, conn, config):
        self.conn = conn
        self.config = config

    @contextmanager
    def log_timed_query(self, query):
        start_time = time.time()
        log_data = self.build_log_data(query)
        try:
            yield log_data
        except:
            log_data['threadid'] = -1
            raise
        finally:
            end_time = time.time()
            log_data['time'] = start_time
            log_data['elapsed'] = elapsed = (end_time - start_time) * 1000
            self.log_query(log_data)

        self.log_slow_query(elapsed, log_data)

    def log_slow_query(self, elapsed, log_data):
        if self.config.slow_logging and elapsed >= config.slow_query_logger_threshold:
            log_data['source'] = current_source
            # TODO: This would benefit from yelp_logging.proto_encode
            clog.log_line('tmp_slow_queries', log_data.to_json(keys=log_data.slow_query_keys))

    def print_query(self, log_data):
        if self.config.printing:
            # nb: \e[38;5;#m is the xterm 256-color escape code.  These colors
            # are a medium blue/azure/aqua followed by a light gray query,
            # chosen to be readable and easy to find (i.e. unlikely to be used
            # by any other output) but also very easy to distinguish from plain
            # stdout/stderr.  The latter is particularly important since this
            # logging tends to generate A LOT of spew.
            sys.stdout.write(
                "\033[38;5;25m{0.name} "
                "\033[38;5;31m{0.thread_id} "
                "\033[38;5;37m{0.db_params[0]}:{0.db_params[1]} "
                "\033[38;5;248m{0.query}"
                "\033[39m\n"
                .format(log_data)
            )
            sys.stdout.flush()

    def log_explain(self, explain_data, query, filled_query):
        self.print_explain(explain_data)

        if not self.config.explain:
            return

        log_data = self.build_log_data(query, filled_query)
        scores = calc_explain_plan_scores(explain_data)
        log_data['result'] = explain_data
        log_data['highlight'] = sum(scores.values()) >= 1.0
        self.notify_listeners(log_data.to_dict(), action='on_explain_plan')

    def print_explain(self, explain_data):
        if self.config.explain_printing:
            cols = ['id', 'select_type', 'table', 'type', 'possible_keys', 'key',
                'key_len', 'ref', 'rows', 'Extra']
            pp_str = format_sql_table(explain_data, order_columns=cols)
            self.print_query(pp_str)

    def build_log_data(self, query, filled_query=None):
        return LogData.from_conn_and_query(self.conn, query, filled_query)

    def log_query(self, log_data):
        if not self.config.enabled_for(log_data.query):
            return

        self.print_query(log_data)
        if self.config.logging:
            self.notify_listeners(log_data.to_dict(), action='on_query')

    def notify_listeners(self, log_data, action='on_query'):
        """Send logging data to each of the listeners."""
        for listener in self.config.listeners:
            getattr(listener, action)(log_data)


def filter_by_keys(d, keys):
    if not keys:
        return d
    keys = set(keys)
    return dict((k, v) for (k, v) in d.iteritems() if k in keys)


class LogData(object):
    """Data object for serializing details about a query. Used to defer the
    execution of expensive operations until the log is actually written.
    """

    slow_query_keys = ['time', 'query', 'dbparams', 'client', 'name', 'elapsed', 'source']

    def __init__(self, query, name, thread_id, db_params, filled_query=None):
        self.query = query
        self.filled_query = filled_query
        self.name = name
        self.thread_id = thread_id
        self.db_params = db_params
        self.extra = {}
        self._call_stack = None

    @property
    def call_stack(self):
        if self._call_stack:
            return self._call_stack
        self._call_stack = showstack(5)
        return self._call_stack

    @classmethod
    def from_conn_and_query(cls, conn, query, filled_query=None):
        db_params = get_db_params_from_conn(conn)
        return cls(query, conn.name, conn.thread_id(), db_params, filled_query)

    def __setitem__(self, key, value):
        self.extra[key] = value

    def to_json(self, keys=None):
        return json.dumps(self.to_dict(keys))

    def to_dict(self, keys=None):
        details = {
            'query': canonicalize_sql_query(self.query),
            'filled_query': self.filled_query or self.query,
            'name': self.name,
            'threadid': self.thread_id,
            'callstack': self.call_stack,
            'client': socket.gethostname(),
            'dbparams': self.db_params
        }
        details.update(self.extra)
        return filter_by_keys(details, keys)


@contextmanager
def log_context(name):
    """ Store original source so we may restore it later"""
    global current_source
    orig = current_source
    current_source = name
    try:
        yield
    finally:
        current_source = orig

def showstack(startat=1, separator='->'):
    """Format a stack trace for logging."""
    # This would be a bit easier with the traceback module, but that would also
    # fetch actual lines of source code, which is relatively expensive and
    # which we would immediately discard.
    frame_lines = []
    frame = sys._getframe(startat)
    while frame:
        co = frame.f_code
        filename = co.co_filename
        filename = os.path.basename(co.co_filename)
        frame_lines.append(
            '%s (%s:%s)' % (co.co_name, frame.f_lineno, filename))

        frame = frame.f_back

    frame_lines.reverse()
    return separator.join(frame_lines)
