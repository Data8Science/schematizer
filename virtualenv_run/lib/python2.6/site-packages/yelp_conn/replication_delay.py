# -*- coding: utf-8 -*-
"""Replication Delay Service Client

Utility for querying the replication delay service, which returns the
replication delay for a cluster of mysql databases.

Example

.. code-block:: python

    from yelp_conn import replication_delay

    # Get the current max replication delay from a cluster name
    delay = replication_delay.replication_delay(cluster='replication')

    # List of cluster names from topology.yaml
    clusters = ['replication']

    # Sleep until replication is within a threshold
    replication_delay.throttle_to_replication(clusters)

    # Sleep until replication has caught up to "now"
    replication_delay.wait_for_replication(clusters)

"""
import httplib
import logging
import time
import socket
import os

import clog
import requests
from requests.packages.urllib3.exceptions import TimeoutError
import simplejson as json

from yelp_conn import config
from yelp_conn._retry_decorators import retry_on_exception


DELAY_PATH = 'repl_delay/show'

DEFAULT_TIMEOUT = 6.0

MAX_THROTTLE_DELAY = 3.0


log = logging.getLogger(__name__)


replication_delay_host = config.conn_conf.get_string(
    'replication_delay_params.host',
    default="localhost",
    help="Hostname for the replication delay service.")


replication_delay_port = config.conn_conf.get_int(
    'replication_delay_params.port',
    default=0,
    help="Port number for the replication delay service.")


class ReplicationDelayError(Exception):
    """Error raised when connecting to the service fails."""
    pass


class ReplicationDelaySocketTimeout(ReplicationDelayError):
    """Occurs when the service is unreachable"""
    pass


class ReplicationNotCaughtUp(Exception):
    """The replication delay service worked correctly,
    but replication did not catch up.
    """
    pass


def replication_delay(cluster='replication', timeout=DEFAULT_TIMEOUT):
    """Get the maximum replication delay in seconds for the cluster.

    :param cluster: The cluster name from topology. If a cluster has a
                    rdr_cluster property, that name is used.
    :type  cluster: string
    :param timeout: Number of seconds to wait for a response from the server
    :type  timeout: float
    :returns: the delay in seconds
    :rtype: float
    :raises ReplicationDelaySocketTimeout: when request to service hits timeout
    :raises ReplicationDelayError: on a connection error,
                                   or unexpected response from service.
    """
    url = "http://{host}:{port}/{path}/{type}".format(
        host=replication_delay_host.value,
        port=replication_delay_port.value,
        path=DELAY_PATH,
        type=cluster)

    try:
        response = requests.get(url, timeout=timeout)
        delay_value = response.text
    except (requests.exceptions.Timeout, socket.timeout) as e:
        raise ReplicationDelaySocketTimeout(str(e))
    except (requests.exceptions.RequestException,
            socket.gaierror, httplib.HTTPException, IOError) as e:
        # requests v2.4.0 wraps these timeouts in ConnectionError
        if len(e.args) > 0 and isinstance(e.args[0], TimeoutError):
            raise ReplicationDelaySocketTimeout(str(e))
        raise ReplicationDelayError(e)

    try:
        return float(delay_value)
    except ValueError as e:
        raise ReplicationDelayError(str(e))


# retryable exceptions that can be thrown by
# the above basic service-querying code
REPLICATION_DELAY_RETRYABLE_EXCEPTIONS = (
    ReplicationDelaySocketTimeout, ReplicationDelayError, TypeError, ValueError
)


def _wait_for_replication_base(clusters,
                               condition,
                               poll_interval=1.0,
                               max_wait_time=60,
                               retries=5):
    """Hidden base function for replication waiting.

    Call either wait_for_replication or throttle_to_replication
    """

    @retry_on_exception(REPLICATION_DELAY_RETRYABLE_EXCEPTIONS,
                        max_number_of_retries=retries,
                        delay=10)
    def get_with_retries(cluster):
        return replication_delay(cluster)

    clusters = list(set(clusters))
    actual_start_time = now = time.time()
    waited_times = 0
    while (now - actual_start_time) < max_wait_time:
        cluster_delays = [get_with_retries(cluster) for cluster in clusters]
        if condition(cluster_delays):
            return

        waited_times += 1
        log_line = {
            'mode': condition.__name__,
            'pid': os.getpid(),
            'host': socket.gethostname(),
            'time': now,
            'waiting_for': now - actual_start_time,
            'max_wait_time': max_wait_time,
            'clusters': clusters,
            'waited_times': waited_times,
        }
        clog.log_line('tmp_waiting_for_replication', json.dumps(log_line))
        time.sleep(poll_interval)
        now = time.time()

    raise ReplicationNotCaughtUp(
        "Waited maximum %d seconds and never caught up" % max_wait_time)


def throttle_to_replication(clusters,
                            max_delay=MAX_THROTTLE_DELAY,
                            poll_interval=1.0,
                            max_wait_time=60 * 60 * 2,
                            retries=5):
    """Waits for replication on all clusters to be less than `max_delay`.

    Use this to throttle inserts, so that replication delay on slave hosts
    remains within `max_delay` seconds.

    :param clusters: list of cluster names from topology
    :param max_delay: threshold in seconds
    :param poll_interval: seconds to sleep between requests to the service
                          (default 1s)
    :type  poll_interval: float
    :param max_wait_time: maximum seconds to wait (defaults to 2 hours)
    :param retries: number of times to retry a service request (default 5)
    :raises ReplicationNotCaughtUp: if replication does not catch up within
                                    `max_wait_time`
    """
    def throttle(cluster_delays):
        if max(cluster_delays) <= max_delay:
            return True
        log.info('Waiting for heartbeat to be less than %f.', max_delay)

    return _wait_for_replication_base(clusters,
                                      throttle,
                                      poll_interval=poll_interval,
                                      max_wait_time=max_wait_time,
                                      retries=retries)


def wait_for_replication(clusters,
                         poll_interval=1.0,
                         start_time=None,
                         max_wait_time=60 * 60 * 4,
                         retries=5):
    """Waits for replication on all of `clusters` to catch up to the
    point at which the function was invoked. This implementation will
    return immediately if replication is caught up, i.e., all clusters
    are reporting a delay of 0.

    Use this to the wait for an insert to reach a slave.

    :param clusters: list of cluster names from topology
    :param poll_interval: seconds to sleep between requests to the service
                          (default 1s)
    :type  poll_interval: float
    :param start_time: timestamp for `now` (defaults to :func:`time.time`)
    :param max_wait_time: maximum seconds to wait (defaults to 2 hours)
    :param retries: number of times to retry a service request (default 5)
    :raises ReplicationNotCaughtUp: if replication does not catch up within
                                    `max_wait_time`

    """
    start_time = int(start_time or time.time())

    def catch_up(cluster_delays):
        # we want a lower bound on the position of the replication heartbeat
        # on each cluster; we can do this safely by measuring the time locally,
        # then estimating the position as that time minus the replication delay
        now = int(time.time())
        heartbeat_positions = [now - delay for delay in cluster_delays]
        if start_time <= min(heartbeat_positions):
            return True
        log.info('Waiting for heartbeat to catch up to %d.', start_time)

    return _wait_for_replication_base(clusters,
                                      catch_up,
                                      poll_interval=poll_interval,
                                      max_wait_time=max_wait_time,
                                      retries=retries)


if __name__ == '__main__':
    print replication_delay()
