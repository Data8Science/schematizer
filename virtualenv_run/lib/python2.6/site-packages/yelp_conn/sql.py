# -*- coding: utf-8 -*-
"""
Utility methods for generating/manipulating raw SQL. Nothing in here should depend on a connection/cursor.
Copied from yelp_lib.
"""
import math
import re

def order_of_magnitude(x):
    """Returns a number as an order of magnitude

    .. code-block:: python

       order_of_magnitude(1024) # => "thousands"

    :param x: the number
    :type x: int
    :returns: magniture as a string.
    """
    magnitudes = ('ones', 'tens', 'hundreds', 'thousands', 'tens of thousands',
                  'hundreds of thousands', 'millions', 'tens of millions',
                  'hundreds of millions', 'billions')
    pow_of_ten = int(math.log10(x))
    if pow_of_ten > 9:
        return 'many'
    else:
        return magnitudes[pow_of_ten]

csq_in_re = re.compile(r' in \((?P<in_clause>\(.*?\)|[^()]*)*\)', re.IGNORECASE)
def csq_in_sub(q):
    return csq_in_re.sub(lambda x: ' IN (/* %s */)' % order_of_magnitude(len(x.group('in_clause').split(','))), q)

csq_bk_re = re.compile(r'%\(bk[0-9]*\)s', re.IGNORECASE)
def csq_bk_sub(q):
    return csq_bk_re.sub('%(bk...)s', q)

csq_limit_re = re.compile(r'LIMIT *[0-9]+( *, *[0-9]+)?', re.IGNORECASE)
def csq_limit_sub(q):
    return csq_limit_re.sub('LIMIT ...', q)

# Optionally reduce columns selected This feature is very assy, since
# to do this properly, you'll need a real sqlparser and not just some
# re trickeries. Ie. columns names are treated case sensitive and such...
csrq_column_re = re.compile('([a-z][\.\w]+\s+AS\s+[a-z][\.\w]+[\s,]+|[a-z][\.\w]+[\s,]+)')
csrq_mysql_select_words = ['ALL', 'DISTINCT', 'DISTINCTROW' ,'HIGH_PRIORITY', 'STRAIGHT_JOIN', 'SQL_SMALL_RESULT', 'SQL_BIG_RESULT','SQL_BUFFER_RESULT', 'SQL_CACHE' ,'SQL_NO_CACHE', 'SQL_CALC_FOUND_ROWS']
def csq_reduce_columns(q):

    # Now, before you go amok about how this isn't "right" or how it's
    # gross. It covers 99% of our queries sensibly. The ones that it
    # messes up on, are batshit crazy subqueryheavy things.

    # With that said, let the C++ char* style parsing begin. If you
    # can sqlparse or regexp improve this. Go nuts.

    head_pos = 0
    select_keyword = 'SELECT '
    select_pos = q.find(select_keyword)
    mysql_selected_words = []
    while select_pos >= 0:
        select_pos += len(select_keyword)
        pos = select_pos

        # We must already be already be called with excess whitespace having been reduced.
        space_pos = q.find(' ', pos) - pos
        #mysql_selected_words = [word for word in csrq_mysql_select_words if word in q]
        while space_pos >= 0:
            word = q[pos:pos+space_pos]
            if word in csrq_mysql_select_words:
                mysql_selected_words.append(word)
                pos += space_pos + 1
                space_pos = q.find(' ', pos) - pos
            else:
                break

        columns = 0
        while pos >= 0:
            m = csrq_column_re.match(q, pos)
            if m:
                pos += len(m.group(0))
                columns += 1
            else:
                break
        if columns > 0:
            result = q[head_pos:select_pos]
            if mysql_selected_words:
                result += ' '.join(mysql_selected_words) + ' '
            result += '/* ' + order_of_magnitude(columns) + ' */'
            if not q[pos:].strip().startswith('FROM'):
                result += ','
            result += ' ' + q[pos:]
            return result
        select_pos = q.find(select_keyword, select_pos)
    return q

def canonicalize_sql_query(query):
    """
    Take SQL query text (with bindvals) and transform it to a more canonical form
    such that queries that are basically the same (but with different bind values)
    map to the exact same text.
    """
    return csq_limit_sub(csq_bk_sub(csq_in_sub(query))).replace('    ', ' ').replace('\n', ' ').replace('\t', ' ')

#
# regexes for canonicalize_raw_sql_query function
#

# match any run of continugous whitespace
crsq_whitespace_re = re.compile(r'\s+')

# match single quote followed by any chars then single quote (not preceded by backslash).
# do non-greedy match on chars inside quotes
crsq_singleq_string_re = re.compile(r"'(?:\\'|[^'])*'")

# match double quote followed by any chars then double quote (not preceded by backslash).
# do non-greedy match on chars inside quotes
crsq_doubleq_string_re = re.compile(r'"(?:\\"|[^"])*"')

# match optional minus, then digits, then decimal point, then digits.
# use lookahead/behind to make sure we don't have adjacent alphanumeric
crsq_float_re = re.compile(r'(?<!\w)-?[0-9]+\.[0-9]*(?!\w)')

# match optional minus, optional hex marker, then digits.
# use lookahead/behind to make sure we don't have adjacent alphanumeric (e.g. so we don't match 'address2')
crsq_integer_re = re.compile(r'(?<!\w)-?(0x)?[0-9]+(?!\w)')

# match parenthesized list preceded by 'in' or 'IN'.  use non-greedy match inside parens.
# this is not very robust, so must run after other regexs have handled whitespace, string constants, etc.
crsq_in_re = re.compile(r'(?<=in )\((?P<in_clause>[^)]*?)\)', re.I)

# match a values clause with multiple tuples.
# the values keyword and first tuple are grouped so that we can pull them out.
crsq_values_re = re.compile(r'(values \([^)]*?\))(\s*,\s*\([^)]*?\))+', re.I)

# Optionally remove all comments
crsq_comment_re = re.compile(r'(/\*([^*]|[\r\n]|(\*+([^*/]|[\r\n])))*\*+/)')

hostname_comment_re = re.compile(r'(/\* )([A-Za-z0-9.-]+\.[0-9]+ ; )([^*]*\*/)$')
line_number_comment_re = re.compile(r'(/\* [^:]+)(:[0-9]+)( \*/)$')

def filter_annotated_query(query, remove_hostname=True, remove_line_number=True):
    """
    Filter out components from yelp-main annotated queries.
    """
    if remove_hostname:
        query = hostname_comment_re.sub(r'\1\3', query)
    if remove_line_number:
        query = line_number_comment_re.sub(r'\1\3', query)
    return query

def canonicalize_raw_sql_query(query, remove_comments=False, remove_hostname_from_comment=False, remove_line_number_from_comment=False, remove_columns=False):
    """
    Take raw SQL query text (no bindvals) and transform it to a canonical form
    such that queries that are basically the same (but with different constants)
    map to the exact same text. And strips tailing/leading whitespace.

    Args:
       query -- raw query (without bound vals) to normalize
       remove_comments -- optionally strip out all comments
       remove_hostname_from_comment -- remove the hostname from the comment using yelp-main query annotation
       remove_line_number_from_comment -- remove the line_number from the comment using yelp-main query annotation
       remove_columns -- optionally replace SELECT col1, col2 FROM with SELECT * FROM
    """
    # Remove comments before doing the order of magnitudes, since that inserts comments.
    if remove_comments:
        query = crsq_comment_re.sub(' ', query)
    else:
        query = filter_annotated_query(query, remove_hostname=remove_hostname_from_comment, remove_line_number=remove_line_number_from_comment)
    query = crsq_whitespace_re.sub(lambda x: ' ', query) # normalize whitespace first to make some later regexes simpler
    query = crsq_singleq_string_re.sub(lambda x: '%s', query)
    query = crsq_doubleq_string_re.sub(lambda x: '%s', query)
    query = crsq_float_re.sub(lambda x: '%f', query) # do this before integer so that we don't have 123.456 become %d.%d
    query = crsq_integer_re.sub(lambda x: '%d', query)
    # do this last because matching is not very robust
    query = crsq_in_re.sub(lambda x: '(/* %s */)' % order_of_magnitude(len(x.group('in_clause').split(','))), query)
    # if more than one values tuple, leave only first one and add ellipsis
    query = crsq_values_re.sub(lambda match: match.group(1) + ', ...', query)
    if remove_columns:
        query = csq_reduce_columns(query)

    return query.strip()

def format_sql_table(data, order_columns=None, sep='\n'):
    """
    Helper method to pretty print a list of dictionaries (where each dict has the same keys).
    Written for prettyprinting explain results, but anything of the form of
    [{k:v k':v'...}, {k:v, k':v'...} ....]
    should work.

    Args:
       data, list of dicts, [{k:v k':v'...}, {k:v, k':v'...} ....]
       order_columns, optional list of the order to print columns. Used as "hint", in that all extra columns are tacked on at the end. Any columns in this list, that are not in the data set, are dropped.
       sep, line separator
    Returns:
       pretty printed string
    """

    if not data:
        return ''

    lengths = []
    rules = []
    first = data[0]
    keys = first.keys()

    if order_columns:
        new_keys = [column for column in order_columns if column in keys]
        remaining_keys = [column for column in keys if column not in new_keys]
        keys = new_keys + remaining_keys

    for key in keys:
        lengths.append(len(key))

    for col in range(len(lengths)):
        for row in data:
            rls = [len(str(row.get(key))) for key in keys]
            lengths[col] = max(rls[col], lengths[col])
        rules.append("-"*lengths[col])

    format = " ".join(["%%-%ss" % l for l in lengths])
    result = [format % tuple(keys)]
    result.append(format % tuple(rules))
    for row in data:
        result.append(format % tuple([row.get(key) for key in keys]))
    return sep.join(result)

def is_select_from_query(query):
    """Return true if this query starts with SELECT, and has a FROM clause."""
    query = query.upper().strip()
    return query.startswith('SELECT') and 'FROM' in query
