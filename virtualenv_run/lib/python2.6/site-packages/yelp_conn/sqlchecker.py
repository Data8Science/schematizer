# -*- coding: utf-8 -*-
"""Wrapper for doing EXPLAIN plan analysis of queries at runtime."""
import logging
import math
import simplejson as json
import time
import traceback
from contextlib import contextmanager

import clog

from yelp_conn import _import, wrappers
from yelp_conn import config
from yelp_conn.db_util import fetchall_rows_to_dict
from yelp_conn.sql import canonicalize_raw_sql_query, is_select_from_query
from yelp_conn.wrappers import DelegatingConnectionWrapper
from yelp_conn.wrappers import DelegatingCursorWrapper

log = logging.getLogger(__name__)
explain_plan_check_score_threshold = 3.0

def _make_explain_check_context_manager(state):
    @contextmanager
    def explain_plan_checks():
        """
        Context manager to temporarily turn off/on explain checks.
        Only to be used in certain unit-tests that specifically test sqlchecker and sqllogger.
        Do NOT use this just to circumvent the explain checks.
        """
        old_val = CheckExplainCursorWrapper.enabled
        CheckExplainCursorWrapper.enabled = state
        try:
            yield
        finally:
            CheckExplainCursorWrapper.enabled = old_val

    return explain_plan_checks


explain_plan_checks_on = _make_explain_check_context_manager(True)


explain_plan_checks_off = _make_explain_check_context_manager(False)


class GrossQueryError(Exception):
    """
    Exception thrown by CheckExplainCursorWrapper if a query's explain
    plan looks gross.
    """
    def __init__(self, analysis, canonical_query, filled_query):
        super(GrossQueryError, self).__init__()
        self.analysis = analysis
        self.canonical_query = canonical_query
        self.filled_query = filled_query

    def __str__(self):
        return 'Score=%f %s, query=%s (full query=%s) (see https://trac.yelpcorp.com/wiki/GrossQueryError)' % (self.analysis['score'], self.analysis['subscores'], self.canonical_query, self.filled_query)

    def __repr__(self):
        return 'GrossQueryError(analysis=%r, canonical_query=%r, filled_query=%r) (see https://trac.yelpcorp.com/wiki/GrossQueryError)' % (self.analysis, self.canonical_query, self.filled_query)


def calc_explain_plan_scores(explain, columns_description=None, small_table_threshold=20):
    """
    Check query for badness from the explain data

    Note: the explain argument can/should be augmented with 1 extra
    column per row, named 'rows_total' with indicates the total number
    of rows in the table.

    Args:
       explain -- a list of dictionaries containing mysql explain data. [{'rows':x, 'type':'foo'...},...]
       columns_description -- a result of running the query and getting cursor.description, used to account for things that create enormous data sets.

    Returns:
       {'checker': subscore, ...}
       The score is a floating point number describing the score of the explain
       plain with 1.0 and above being bad. The dict of checks and their individual scores.
        The total score is easily obtained by
           scores = calc_explain_plan_scores(...)
            score = sum(scores.values())
    """

    #
    # These helper classes are the various metrics used for checking a
    # plan. Each class get's called for each row in the plan, and sets
    # a .result value describing the plan.
    #
    # In you want to add a metric, simply add a functor that has a
    # 'result' field, can be called for each row in the explain plan.
    #

    class FullTableScan(object):
        """
        Check if the explain plan includes full table scans
        """
        ## Scanning a full table with a "where" clause, probably bad.
        PTS_LIMITED_TABLE_SCAN = 0.50

        ## Scanning a full table, really bad, but not 1.0 since the
        ## table might just be small
        ## (replication_heartbeat). TooManyRowsRowsRows will add enough .1s
        ## if the table is too big.
        PTS_FULL_TABLE_SCAN = 0.9

        def __init__(self):
            self.result = 0.0

        def __call__(self, row):
            if row['type'] == 'ALL':
                if row['Extra'].find('Using where;') >=0:
                    self.result += FullTableScan.PTS_LIMITED_TABLE_SCAN
                else:
                    self.result += FullTableScan.PTS_FULL_TABLE_SCAN


    class NoKeys(object):
        """
        Check for rows that don't use indexes
        """
        # It's bad, but not 1.0 bad. But this will raise the number,
        # and combined with other counters, will quickly flip the
        # query to 1.0 ++
        PTS = 0.5

        def __init__(self):
            self.result = 0.0

        def __call__(self, row):
            if not row['key']:
                self.result += NoKeys.PTS


    class SubQueries(object):
        """
        Check for subqueries.

        Having a lot of subqueries isn't necessarily bad, but
        indicates the query is complex. This metric is debatable.
        """

        PTS_SUBQUERY = 0.2
        PTS_UNCACHEABLE_SUBQUERY = 0.5

        def __init__(self):
            self.result = 0.0

        def __call__(self, row):
            select_type = row['select_type']
            if select_type == 'DERIVED' or select_type == 'SUBQUERY':
                self.result += SubQueries.PTS_SUBQUERY
            elif select_type == 'UNCACHEABLE SUBQUERY':
                self.result += SubQueries.PTS_UNCACHEABLE_SUBQUERY


    class TooManyRowsRowsRows(object):
        """
        Examines the number of rows examined.

        Computes the product of rows examined, and assigns some <1.0
        number of points PTS per BULK number of rows.

        So eg. if a plan has 1 rows and looks at 12000 rows and BULK
        is 5000, the score will be 2 x PTS.

        But if the plan has 2 rows, and looks at 12000 and 17 rows,
        the product will be 204K rows, and the score climbs to 40 x
        PTS.

        Additionally, this compares the number of rows against the
        total number of rows in the table (if a 'total_rows' key is
        present). And if more than TOTAL_ROWS_CMP (fraction) is
        visited, you win a lot of points.
        """
        # these are very tunable
        PTS_ROWS_PRODUCT = 0.1
        BULK = 5000
        TOTAL_ROWS_CMP = 0.5

        def __init__(self):
            self.result = 0.0
            self.rows_examined = 1

        def __call__(self, row):
            if row['rows'] > 1:
                self.rows_examined = self.rows_examined * row['rows']
                damage = self.rows_examined / TooManyRowsRowsRows.BULK
                if damage > 0:
                    self.result += damage * TooManyRowsRowsRows.PTS_ROWS_PRODUCT
                if 'total_rows' in row and row['total_rows'] > 0:
                    if row['rows'] / row['total_rows'] > TooManyRowsRowsRows.TOTAL_ROWS_CMP:
                        self.result += math.ceil(float(row['rows']) / float(TooManyRowsRowsRows.BULK))


    class SortingALotOfRows(object):
        """
        Look for sorting, this is a debatable metric, but let's try.

        This adds PTS_SORT points per BULK number of rows that is
        being sorted.
        """
        # .1 for each BULK rows getting sorted in a temporary
        PTS_SORT = 0.1
        BULK = 1000

        def __init__(self):
            self.result = 0.0
            self.rows = 1

        def __call__(self, row):
            if row['Extra'].find('Using temporary; Using filesort') >= 0:
                self.result += SortingALotOfRows.PTS_SORT * (row['rows'] / SortingALotOfRows.BULK)


    class SizeOfThings(object):
        """
        Uses the columns_description to estimate the size of temporary tables created.
        """

        PTS_PER_MEG = 0.001

        def __init__(self, columns_description):
            self.columns_description = columns_description
            self.result = 0.0

        def __call__(self, row):
            if not self.columns_description:
                return
            row_size = 0
            for column_name, column_type, _, column_size, _, _, _,  in self.columns_description:
                row_size += column_size
            if row['rows'] > 1:
                self.result += self.PTS_PER_MEG * ((row_size * row['rows']) / (1024*1024))

    # For every metric counter, pass each row in the explain plan to
    # each counter and summarise the result
    counters = [
        FullTableScan(),
        NoKeys(),
        SubQueries(),
        TooManyRowsRowsRows(),
        SortingALotOfRows(),
        SizeOfThings(columns_description),
    ]

    if not 0 < small_table_threshold < 500:
        raise ValueError

    for row in explain:
        if 'total_rows' in row and row['total_rows'] < small_table_threshold:
            continue
        for counter in counters:
            counter(row)

    score = 0
    flags = {}
    for counter in counters:
        if counter.result > 0:
            score += counter.result
            flags[counter.__class__.__name__] = counter.result

    return flags

###
### End public APIs
###

def _augment_explain_plan(cursor, explain):
    """
    Injects extra info into an explain plan.

    For each row in the explain, currently inserts ;
       'total_rows' -- the total number of rows for the 'table' 'row_size'

    This number is used to judge how much of a table is scanned in
    explain plans. Eg. a explain plan that examines 400 rows might be
    fine for a 400K row table, but bad for a 400 row table.

    Args:
       cursor -- a database cursor
       explain -- an explain plan in the form of [{...}, ...]
    """

    # To reduce the number of SHOW TABLE STATUS calls, we cache using
    # the table name, and a TTL. This reduces the amount of calls in
    # devdb a bit. I have no numbers to back me up on this. This may
    # be completely redundant.

    # maps from tablename to (count, timestamp)
    _ROW_COUNT_CACHE = {}

    # The TTL for a _ROW_CACHE_COUNT entry.
    _ROW_COUNT_CACHE_TTL = 600

    # If the cache entry has less than this rows, ignore the TTL. This covers
    # the annoying corner case where a table is empty (eg. a fresh sandbox),
    # and a test SELECTS from it, writes a bunch of rows, then SELECTs again.
    # Without this, we'd cache total_rows == 0, and thereby not be able to
    # detect full table scans
    _IGNORE_TTL_ON_ROWS_LESS_THAN = 100

    def is_valid_table_name(table):
        return bool(cursor.execute('SHOW CREATE TABLE %s' % table) >= 1)

    def normalize_table_name(table):
        try:
            if is_valid_table_name(table):
                return table
        except:
            # Strip out ORM aliasing without actually parsing SQL... ghetto.
            rpos = table.rfind('_')
            if rpos > 0:
                tail = table[rpos + 1:]
                if tail.isdigit():
                    table = table[:rpos]
                    if is_valid_table_name(table):
                        return table
        return None


    def find_total_rows_from_table(table):
        total_rows = 0
        table = normalize_table_name(table)
        if table is None:
            # Some derived explain plan will not have a table name
            # to select on
            return total_rows
        
        if cursor.execute('EXPLAIN SELECT COUNT(*) FROM %s' % table) >= 1:
            total_rows = fetchall_rows_to_dict(cursor)[0]['rows']
            if total_rows is None:
                # I have seen cases in which MyISAM table in which
                # EXPLAIN plan does not provide `rows` data
                # In that case, we fall back on a second way to estimate number of rows
                if cursor.execute('SHOW TABLE STATUS WHERE name = %(table)s', {'table': table}) >= 1:
                    total_rows = fetchall_rows_to_dict(cursor)[0]['Rows']
        return total_rows

    def update(table):
        total_rows = 0

        if not table:
            return ({'total_rows': total_rows}, time.time() + _ROW_COUNT_CACHE_TTL)

        total_rows = find_total_rows_from_table(table)
        cache_entry = ({'total_rows': total_rows}, time.time() + _ROW_COUNT_CACHE_TTL)
        _ROW_COUNT_CACHE[table] = cache_entry
        return cache_entry

    for row in explain:
        table = row['table']

        cache_entry = _ROW_COUNT_CACHE.get(table, None)
        if cache_entry is None:
            values, timestamp = update(table)
        else:
            values, timestamp = cache_entry
            if timestamp < time.time() or values['total_rows'] < _IGNORE_TTL_ON_ROWS_LESS_THAN:
                values, _ = update(table)
        row.update(values)


def _get_explain_plan(cursor, query):
    """
    Run EXPLAIN on the query and return a list of dicts with the result.
    """
    rows = cursor.execute('EXPLAIN %s' % query)
    if rows >= 1:
        return fetchall_rows_to_dict(cursor)
    return []


def get_explain_plan_and_scores(cursor, query):
    """
    Run EXPLAIN on the query and examine the plan for known bad
    things. This will both run 'EXPLAIN query' and possibly also a few
    'SHOW TABLE STATUS WHERE...' queries to examine the tables
    involved.

    Note: query should only be SELECT statements.

    Args:
       cursor -- a database cursor
       query -- the query to examine
    Returns:
       {'score': score, 'subscores': {'checker': score,...}, 'plan': explain plan dict}
    """
    cursor.execute("SHOW SESSION STATUS WHERE Variable_name = 'Created_tmp_disk_tables'")
    start_tmp_disk_tables = int(fetchall_rows_to_dict(cursor)[0]['Value'])

    explain_plan = _get_explain_plan(cursor, query)
    _augment_explain_plan(cursor, explain_plan)

    # This is pretty annoying, but necessary. We run the query to get the column description.
    # This lets us evaluate the size of the the data returned and is usefult to adjust the
    # signals that trigger on sorting rows.
    cursor.execute(query)
    columns_description = cursor.description

    cursor.execute("SHOW SESSION STATUS WHERE Variable_name = 'Created_tmp_disk_tables'")
    tmp_disk_tables = int(fetchall_rows_to_dict(cursor)[0]['Value']) - start_tmp_disk_tables

    scores = calc_explain_plan_scores(explain_plan, columns_description=columns_description, small_table_threshold=config.gross_query_check_table_row_threshold)

    if len(query) > 100000:
        scores.update({u'QueryIsPi\xc3ataOfLength': len(query)/100000})

    # Temporary tables on disks are bad mmkay, and if there's a size of things, that gets ten
    # folded if you're on disk.set-
    if tmp_disk_tables > 0:
        scores.update({'TmpTablesOnSpinningMedia': tmp_disk_tables})
        if 'SizeOfThings' in scores:
            scores['SizeOfThings'] *= 10

    score = sum(scores.values())

    return {'score': score, 'subscores': scores, 'plan': explain_plan}


class ExplainPlanListener(object):
    """config.explain_plan_listeners is a list of these"""

    def on_explain_plan_received(self, explain_data):
        pass

    def on_gross_query_received(self, explain_data):
        pass


def get_last_comment(raw_query):
    """Return the last comment from the raw query."""
    comment_start, comment_stop = raw_query.rfind('/*'), raw_query.rfind('*/')
    if comment_start >= 0 and comment_stop >= 0:
        if raw_query[comment_start:comment_start+7] == '/* yelp':
            return raw_query[comment_start + 2:comment_stop].strip()


class CheckExplainCursorWrapper(DelegatingCursorWrapper):
    """
    Cursor wrapper that runs EXPLAIN on all SELECT...FROM statements,
    analyses the plan and logs suspicious looking plans.

    See calc_explain_plan_scores for the actual plan analysis
    implementation.
    """
    enabled = False

    def __init__(self, conn, cursor):
        super(CheckExplainCursorWrapper, self).__init__(conn, cursor)
        self._threadid = conn.thread_id()

    def _should_check(self, canonical_query):
        return (config.enable_clog_queries or
                canonical_query not in config.whitelisted_queries)

    def _check(self, raw_query, filled_query):
        canonical_query = canonicalize_raw_sql_query(filled_query,
            remove_columns=True, remove_comments=True)

        if not self._should_check(canonical_query):
            return

        if not 0 < config.gross_query_check_threshold < 10:
            raise ValueError('gross query check threshold is too low')

        analysis = get_explain_plan_and_scores(self._delegate, filled_query)
        explain_data = {
            'analysis'       : analysis,
            'filled_query'   : filled_query,
            'canonical_query': canonical_query,
            'connection_name': self.connection.name,
            'last_comment'   : get_last_comment(raw_query),
            'threadid'       : self._threadid,
        }
        self.notify_listeners(explain_data)

    def notify_listeners(self, explain_data):
        for listener in config.explain_plan_listeners:
            if isinstance(listener, basestring):
                # instansiate class and poke
                listener = _import.import_module_class(listener)()
                assert isinstance(listener, ExplainPlanListener)
            elif isinstance(listener, ExplainPlanListener):
                # already an instance, just poke (used by unit test only)
                pass
            else:
                raise ValueError('Invalid on_explain_plain_received listener type %s' % type(listener))

            if explain_data['analysis']['score'] >= config.gross_query_check_threshold:
                listener.on_gross_query_received(explain_data)
            else:
                listener.on_explain_plan_received(explain_data)

    def execute(self, query, bind_vals=None):
        # The check for SELECT...FROM is to prevent running explain on
        # "SELECT FOUND_ROWS()" queries, which would wreck havoc on
        # things since they would then return the number of rows in
        # the explain plan.
        if self.enabled and is_select_from_query(query):
            filled_query = wrappers.fill_query(self._delegate, query, bind_vals)
            self._check(query, filled_query)
        return self._delegate.execute(query, bind_vals)

    def executemany(self, query, bind_vals=None):
        if self.enabled and is_select_from_query(query):
            bind_values = bind_vals[0] if bind_vals else None
            filled_query = wrappers.fill_query(self._delegate, query, bind_values)
            self._check(query, filled_query)
        return self._delegate.executemany(query, bind_vals)


class CheckExplainConnectionWrapper(DelegatingConnectionWrapper):
    """
    Connection wrapper that wraps a CheckExplainCursorWrapper around cursors.
    """
    CURSOR_CLASS = CheckExplainCursorWrapper


class LogGrossQueryErrorToCLog(ExplainPlanListener):

    def __init__(self, *args, **kwargs):
        super(LogGrossQueryErrorToCLog, self).__init__(*args, **kwargs)
        self.__clog_stream = 'tmp_query_log'

    def on_gross_query_received(self, explain_data):
        # don't care about these
        pass

    def on_explain_plan_received(self, explain_data):
        """
        explain_data -- dict; see caller for keys
        """
        analysis = explain_data['analysis']
        filled_query = explain_data['filled_query']
        canonical_query = explain_data['canonical_query']
        connection_name = explain_data['connection_name']
        last_comment = explain_data['last_comment']

        if config.enable_clog_queries:
            info = {'analysis': analysis, 'canonical_query': canonical_query, 'filled_query': filled_query, 'conn': connection_name}
            # As a crutch to find out where which queries are
            # generated (ie. obscure corner case test, something
            # vital, batch job, servlet, admin or main site), we
            # look for yelp/tests/ to find the testcase we're in
            # and stuff that into the scribe log. This is in
            # addition to the last_comment gives a good hint as to
            # where the query originates from and how much effort
            # should be put into fixing it.
            test_files = []
            for line in traceback.format_stack():
                if 'yelp/tests/' in line:
                    test_files.append(line.strip())
            if test_files:
                info['test_case'] = ' '.join(test_files)
            if last_comment:
                info['last_comment'] = last_comment
            clog.log_line(self.__clog_stream, json.dumps(info))
