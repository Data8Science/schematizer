# -*- coding: utf-8 -*-
"""
This module handles the creation of mysql connections from a topology
configuration. It supports retrying a connection on a different host in a cluster
when a connection to a host fails.

This module does not deal with connection failures on already opened connections,
only those failures which happen when a new connection is being opened.
"""
from collections import namedtuple
import logging
import time

import MySQLdb
import MySQLdb.constants.ER
import MySQLdb.constants.CR

from yelp_conn import config
from yelp_conn.getters import setup_mysql_connection
from yelp_lib.ai.bucketing import weighted_choice


log = logging.getLogger(__name__)

FailureRecord = namedtuple('ConnectFailure', 'errcode message timestamp')


# TODO: other codes?
# These error codes are for errors which can happen on the initial connection.
# We do not handle errors which occur with an already opened connection.
failure_op_codes = set((
    MySQLdb.constants.ER.CON_COUNT_ERROR,
    MySQLdb.constants.CR.CONN_HOST_ERROR))


def is_connection_failure(op_code):
    return op_code in failure_op_codes


class ConnectionFilter(object):
    """ConnectionFilter tracks connection failures for each cluster entry.
    If an entry has a connection failure it is removed from the list of hosts.
    FailureRecords expire over time, allowing a failed host to return to the
    list of hosts.

    As a safeguard against overloading working hosts, when too many hosts
    have failed the filtering is disabled so that the remaining live hosts
    are not further overloaded.  Set `min_capacity` to toggle the threshold
    for this safeguard.
    """

    min_capacity = config.conn_conf.get_float(
        'ConnectionFilter.min_capacity',
        default=0.0,
        help="Minimum capacity required by a connection cluster to support "
             "connection filter.")

    failure_record_lifetime = config.conn_conf.get_int(
        'ConnectionFilter.failure_record_lifetime',
        default=60*15,
        help="Number of seconds to keep failure records. After this time they "
             "are discarded. Defaults to 15 minutes.")

    def __init__(self, connection_cluster):
        """
        connection_cluster - a topology.ConnectionCluster object
        """
        self.connection_cluster = connection_cluster
        self.connection_failures = {}

    def get_entries_without_failures(self):
        self.trim_connection_failures()
        failure_filter = lambda e: e not in self.connection_failures
        return filter(failure_filter, self.connection_cluster.entries)

    def get_capacity(self):
        entries = self.get_entries_without_failures()
        current_weight = sum(entry.weight for entry in entries)
        return float(current_weight) / self.connection_cluster.total_weight

    def is_under_capacity(self):
        capacity = self.get_capacity()
        if capacity < self.min_capacity:
            msg = "Cluster %s under minimum capacity (%s): %s"
            log.warn(msg, self.connection_cluster.key, self.min_capacity, capacity)
            return True
        return False

    def add_connection_failure(self, entry, failure):
        self.connection_failures[entry] = failure

    def trim_connection_failures(self):
        """Remove connection failures which are older than
        failure_record_lifetime.
        """
        current_time = time.time()
        lifetime = float(self.failure_record_lifetime.value)
        for entry, failure in self.connection_failures.items():
            if failure.timestamp + lifetime < current_time:
                del self.connection_failures[entry]


class ConnectionCreator(object):
    """Create connections from a topology cluster. Retries connections Uses a
    ConnectionFilter object to gracefully handle connection failures.
    """
    enable_retries = config.conn_conf.get_bool(
        'ConnectionCreator.enable_retries',
        default=False,
        help="Flag to enable this filter. Defaults to False.")

    def __init__(self, connection_def, connection_cluster):
        """
        connection_def - a topology.ConnectionDef object
        connection_cluster - a topology.ConnectionCluster object
        """
        self.connection_def = connection_def
        self.connection_cluster = connection_cluster
        self.connection_filter = ConnectionFilter(self.connection_cluster)

    def __call__(self):
        """Returns a MySql DBI connection."""
        if self.connection_cluster.num_entries == 1:
            return self.connect(self.connection_cluster.entries[0])

        if self.enable_retries:
            return self.connect_with_retries()

        return self.connect_without_filtering()

    def connect_with_retries(self):
        while True:
            if self.connection_filter.is_under_capacity():
                return self.connect_without_filtering()

            entry = self.get_conn_entry()
            try:
                return self.connect(entry)
            except MySQLdb.OperationalError as exc:
                self.handle_connect_failure(exc, entry)

    def connect_without_filtering(self):
        entries = self.connection_cluster.entries
        return self.connect(self.get_weighted_choice(entries))

    def handle_connect_failure(self, exc, entry):
        err_code, message = exc.args
        if not is_connection_failure(err_code):
            raise

        log.warn("Connect (%s) failed: %s", entry, exc)
        failure = FailureRecord(err_code, message, time.time())
        self.connection_filter.add_connection_failure(entry, failure)

    def connect(self, connection_entry):
        return setup_mysql_connection(
            str(self.connection_def),
            connection_entry.params,
            auto_commit=self.connection_def.auto_commit,
            cluster=self.connection_cluster.cluster_name)

    def get_conn_entry(self):
        entries = self.connection_filter.get_entries_without_failures()
        return self.get_weighted_choice(entries)

    def get_weighted_choice(self, entries):
        return weighted_choice((entry, entry.weight) for entry in entries)
